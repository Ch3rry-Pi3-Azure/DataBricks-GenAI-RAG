{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "749d8baf-717e-4cf3-84b0-ad012d16e9ac",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# <span style=\"color:#1f77b4\">**Generative AI 01 - Basic ChatBot**</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "208be558-8dc5-4b1d-af49-a97e18ae4f5e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## <span style=\"color:#1f77b4\">**Configure OpenAI secrets**</span>\n\nLoad the Azure OpenAI endpoint, key, API version, and deployment name from the Databricks secret scope so they are not hardcoded.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ea080713-bc4a-466b-a247-d79163dadb7c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "# Load secrets from the Databricks-backed Key Vault scope and store them as env vars\n",
    "scope = \"aoai-scope\"\n",
    "os.environ[\"OPENAI_API_BASE\"] = dbutils.secrets.get(scope, \"openai-api-base\")\n",
    "os.environ[\"OPENAI_API_KEY\"] = dbutils.secrets.get(scope, \"openai-api-key\")\n",
    "os.environ[\"OPENAI_API_VERSION\"] = dbutils.secrets.get(scope, \"openai-api-version\")\n",
    "os.environ[\"OPENAI_DEPLOYMENT_NAME\"] = dbutils.secrets.get(scope, \"openai-deployment-name\")\n",
    "\n",
    "# Initialize the Azure OpenAI client once for reuse in this notebook\n",
    "openai_client = AzureOpenAI(\n",
    "    azure_endpoint=os.environ[\"OPENAI_API_BASE\"],\n",
    "    api_key=os.environ[\"OPENAI_API_KEY\"],\n",
    "    api_version=os.environ[\"OPENAI_API_VERSION\"],\n",
    ")\n",
    "\n",
    "# Keep the deployment name handy for later calls\n",
    "deployment_name = os.environ[\"OPENAI_DEPLOYMENT_NAME\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9b36622f-8dcf-4427-a164-5807bf32effa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## <span style=\"color:#1f77b4\">**Chat Completions setup**</span>\n\nDefine the system and user prompts and send them to the Azure OpenAI deployment using the chat completions API.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0dc16c60-bcec-4bb4-9caa-5c2deb19594a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### <span style=\"color:#1f77b4\">**Define the system prompt**</span>\n\nThe system prompt sets the assistant behavior and tone for the response.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "79adc578-b53e-445e-9cb1-6ae72aeab0ab",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# System prompt sets the assistant behavior for all completions\n",
    "system_prompt = f\"\"\" You are a helpful AI assistant meant to answer the user query \"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b7d54d4a-a433-4828-85fe-491953c99c4c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### <span style=\"color:#1f77b4\">**Define the user prompt**</span>\n\nThe user prompt is the query we want the assistant to answer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b082e7b4-0b47-4ead-82cb-2485b15bd779",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# User prompt is the question we send to the model\n",
    "user_prompt = f\"\"\" Hi how are you?\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "78c9b3b6-7119-4d26-93da-b36096548e2f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### <span style=\"color:#1f77b4\">**Call the GPT deployment**</span>\n\nCall the deployment and print the assistant response text.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b4d8d6b0-8e48-4f30-864c-d7ab21238c54",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Hi there! I\u2019m just a bunch of code, so I don\u2019t have feelings, but I\u2019m here and ready to help. \ud83d\ude0a  \nHow are you doing today?\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/databricks.mlflow.trace": "\"tr-f5b01a1aaf8b5eb7b426100f275ddbf9\"",
      "text/plain": [
       "Trace(trace_id=tr-f5b01a1aaf8b5eb7b426100f275ddbf9)"
      ]
     },
     "metadata": {}
    }
   ],
   "source": [
    "# Call the chat completions endpoint with system + user messages\n",
    "gpt_response = openai_client.chat.completions.create(\n",
    "    model = deployment_name,\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\":\"system\", \"content\": f\"{system_prompt}\"\n",
    "        },\n",
    "        {\n",
    "            \"role\":\"user\", \"content\": f\"{user_prompt}\"\n",
    "        }\n",
    "    ],\n",
    "    temperature = 0.7\n",
    ")\n",
    "\n",
    "# Print the assistant response text\n",
    "print(gpt_response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a40291fb-5327-4190-a2e9-f7ad726259fa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## <span style=\"color:#1f77b4\">**Wrap as an MLflow pyfunc**</span>\n\nCreate a PythonModel wrapper so the chat logic can be logged and served from MLflow.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cedc3333-394c-49c7-b489-bc5da8258dc1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/databricks/python/lib/python3.12/site-packages/mlflow/pyfunc/utils/data_validation.py:155: FutureWarning: Model's `predict` method contains invalid parameters: {'data'}. Only the following parameter names are allowed: context, model_input, and params. Note that invalid parameters will no longer be permitted in future versions.\n  param_names = _check_func_signature(func, \"predict\")\n/databricks/python/lib/python3.12/site-packages/mlflow/pyfunc/utils/data_validation.py:186: UserWarning: \u001b[33mAdd type hints to the `predict` method to enable data validation and automatic signature inference during model logging. Check https://mlflow.org/docs/latest/model/python_model.html#type-hint-usage-in-pythonmodel for more details.\u001b[0m\n  color_warning(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import mlflow\n",
    "from mlflow import pyfunc\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "# Wrap Azure OpenAI calls as an MLflow pyfunc so it can be served\n",
    "class BasicChatBot(pyfunc.PythonModel):\n",
    "      def _get_client(self):\n",
    "          # Build a client from env vars injected by the serving endpoint\n",
    "          return AzureOpenAI(\n",
    "            azure_endpoint=os.environ[\"OPENAI_API_BASE\"],\n",
    "            api_key=os.environ[\"OPENAI_API_KEY\"],\n",
    "            api_version=os.environ[\"OPENAI_API_VERSION\"],\n",
    "          )\n",
    "\n",
    "      def chatCompletionsAPI(self, user_query):\n",
    "          # Create a single completion for the provided user query\n",
    "          response = self._get_client().chat.completions.create(\n",
    "            model = os.environ[\"OPENAI_DEPLOYMENT_NAME\"],\n",
    "            messages = [\n",
    "                {\n",
    "                    \"role\":\"system\",\n",
    "                    \"content\":\"You are a helpful AI assistant\"\n",
    "                },\n",
    "                {\n",
    "                    \"role\":\"user\",\n",
    "                    \"content\":f\"{user_query}\"\n",
    "                }\n",
    "            ],\n",
    "            temperature = 0.7\n",
    "          )\n",
    "\n",
    "          return response.choices[0].message.content\n",
    "\n",
    "      def predict(self, context, data):\n",
    "          # MLflow passes a pandas DataFrame; extract the user_query column\n",
    "          user_query = data[\"user_query\"].iloc[0]\n",
    "          gpt_response = self.chatCompletionsAPI(user_query)\n",
    "          return gpt_response\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "be67966a-ad53-4a9e-bc40-75751b106a97",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## <span style=\"color:#1f77b4\">**Save the model locally**</span>\n\nSave the pyfunc model to a local artifact directory with a signature and input example.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "94e7bac5-75ff-42a9-a3d8-9bc23315695f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Instantiate the model wrapper for saving and testing\n",
    "test_model = BasicChatBot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c6072a8b-0234-4144-93f2-77fc7830ea2f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2025/12/30 20:18:34 INFO mlflow.pyfunc: Validating input example against model signature\n"
     ]
    }
   ],
   "source": [
    "from mlflow.models import infer_signature\n",
    "import pandas as pd\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "# Provide an input example for signature inference\n",
    "input_example = pd.DataFrame([{\"user_query\": \"hello how are you?\"}])\n",
    "signature = infer_signature(input_example)\n",
    "model_path = \"basicchatbot\"\n",
    "\n",
    "# Remove existing directory to avoid save conflicts on reruns\n",
    "model_dir = Path(model_path)\n",
    "if model_dir.exists():\n",
    "    shutil.rmtree(model_dir)\n",
    "\n",
    "# Save the pyfunc model locally\n",
    "mlflow.pyfunc.save_model(\n",
    "    path=model_path,\n",
    "    python_model=test_model,\n",
    "    signature=signature,\n",
    "    input_example=input_example,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "106770fe-d403-4062-84f4-a0184f3a6acb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## <span style=\"color:#1f77b4\">**Load the saved model**</span>\n\nReload the saved artifact to confirm it can be deserialized.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e2e7e922-d252-4008-bbfe-3be5ff57f8f1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Load our custom model from the local artifact store\n",
    "loaded_pyfunc_model = mlflow.pyfunc.load_model(model_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f5bb8d2a-eaaa-431b-884c-95cc93cc4822",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## <span style=\"color:#1f77b4\">**Test the saved model**</span>\n\nRun a sample inference to validate the predict path.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5da6e478-331b-4490-ba01-0773d45964b6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Hello! I\u2019m just a program, so I don\u2019t have feelings, but I\u2019m here and ready to help you. \ud83d\ude0a  \nHow are you doing today?\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/databricks.mlflow.trace": "\"tr-37fd9cbd1a12ef481546047e530e7077\"",
      "text/plain": [
       "Trace(trace_id=tr-37fd9cbd1a12ef481546047e530e7077)"
      ]
     },
     "metadata": {}
    }
   ],
   "source": [
    "# Run a simple test inference through the saved model\n",
    "model_input = pd.DataFrame([{\"user_query\": \"hello how are you?\"}])\n",
    "\n",
    "model_response = loaded_pyfunc_model.predict(model_input)\n",
    "\n",
    "print(model_response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6b9a479a-2dbd-43a2-9f80-944706c03551",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## <span style=\"color:#1f77b4\">**Register the model in MLflow**</span>\n\nLog and register the model in the workspace registry, then print the latest version.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4e41af5c-53db-49ae-8a2a-b82c97e5d8b0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\ud83d\udd17 View Logged Model at: https://adb-7405605517349658.18.azuredatabricks.net/ml/experiments/2548890231483242/models/m-f88e51486d9b40e5ade6d87602a95304?o=7405605517349658\n2025/12/30 20:20:32 INFO mlflow.pyfunc: Validating input example against model signature\nRegistered model 'basic-chatbot' already exists. Creating a new version of this model...\n2025/12/30 20:22:34 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: basic-chatbot, version 2\nCreated version '2' of model 'basic-chatbot'.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Registered model: basic-chatbot, version: 2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "# Avoid recording env vars (secrets) in model metadata\n",
    "os.environ[\"MLFLOW_RECORD_ENV_VARS_IN_MODEL_LOGGING\"] = \"false\"\n",
    "\n",
    "# Use the workspace registry (not Unity Catalog)\n",
    "mlflow.set_registry_uri(\"databricks\")\n",
    "\n",
    "model_name = \"basic-chatbot\"\n",
    "\n",
    "with mlflow.start_run() as run:\n",
    "    # Log and register the model in one step\n",
    "    mlflow.pyfunc.log_model(\n",
    "        name=\"model\",\n",
    "        python_model=test_model,\n",
    "        signature=signature,\n",
    "        input_example=input_example,\n",
    "        registered_model_name=model_name,\n",
    "    )\n",
    "    client = MlflowClient()\n",
    "    # Find the latest registered version\n",
    "    versions = client.search_model_versions(f\"name='{model_name}'\")\n",
    "    version = max((int(v.version) for v in versions), default=None)\n",
    "    print(f\"Registered model: {model_name}, version: {version}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "164b784a-0510-4429-8a5c-2b64e8693cbc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## <span style=\"color:#1f77b4\">**Query the serving endpoint**</span>\n\nExample payload you can send to the model serving endpoint.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3dbeb63f-170e-46b3-9772-c36093252532",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'dataframe_records': [{'user_query': 'Tell me something interesting about AI'}]}"
      ]
     },
     "execution_count": 11,
     "metadata": {}
    }
   ],
   "source": [
    "# Example serving request payload\n",
    "{\n",
    "  \"dataframe_split\": {\n",
    "    \"columns\": [\n",
    "      \"user_query\"\n",
    "    ],\n",
    "    \"data\": [\n",
    "      [\n",
    "        \"hello how are you?\"\n",
    "      ]\n",
    "    ]\n",
    "  }\n",
    "}\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "basic_chat_bot.ipynb",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}