{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c374180f-9a06-4e57-841c-0c6860e5d560",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# GenAI with Azure Databricks - Developing RAG System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "28f52a3e-fd8d-4472-8046-b6fceccee585",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Loading the csv file into the DBFS (Databricks File System)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c32a7e44-5123-4780-b8c3-9d948cd9fe09",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Configure Unity Catalog widgets and resolve the active catalog.\n",
    "\n",
    "dbutils.widgets.removeAll()\n",
    "dbutils.widgets.text(\"CATALOG\", \"\")\n",
    "dbutils.widgets.text(\"SCHEMA\", \"rag\")\n",
    "dbutils.widgets.text(\"VOLUME\", \"raw\")\n",
    "dbutils.widgets.text(\"EXTERNAL_LOCATION\", \"uc-external-location\")\n",
    "\n",
    "catalog_widget = dbutils.widgets.get(\"CATALOG\")\n",
    "if catalog_widget:\n",
    "    catalog_name = catalog_widget\n",
    "else:\n",
    "    current = spark.sql(\"SELECT current_catalog()\").first()[0]\n",
    "    catalogs = [r.catalog for r in spark.sql(\"SHOW CATALOGS\").collect()]\n",
    "    catalog_name = current if current not in (\"system\",) else next(c for c in catalogs if c not in (\"system\",))\n",
    "\n",
    "schema_name = dbutils.widgets.get(\"SCHEMA\")\n",
    "volume_leaf = dbutils.widgets.get(\"VOLUME\")\n",
    "external_location_name = dbutils.widgets.get(\"EXTERNAL_LOCATION\")\n",
    "\n",
    "table_name = f\"{catalog_name}.{schema_name}.diabetes_faq_table\"\n",
    "index_name = f\"{catalog_name}.{schema_name}.diabetes_faq_index\"\n",
    "volume_name = f\"{catalog_name}.{schema_name}.{volume_leaf}\"\n",
    "\n",
    "spark.sql(f\"CREATE SCHEMA IF NOT EXISTS {catalog_name}.{schema_name}\")\n",
    "\n",
    "location_rows = spark.sql(f\"DESCRIBE EXTERNAL LOCATION `{external_location_name}`\")\n",
    "if \"url\" in location_rows.columns:\n",
    "    external_url = location_rows.select(\"url\").first()[\"url\"].rstrip(\"/\")\n",
    "else:\n",
    "    external_url = location_rows.filter(\"key = \\\"url\\\"\").select(\"value\").first()[\"value\"].rstrip(\"/\")\n",
    "\n",
    "spark.sql(\n",
    "    f\"\"\"CREATE EXTERNAL VOLUME IF NOT EXISTS {volume_name}\n",
    "    LOCATION '{external_url}'\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "data_path = f\"dbfs:/Volumes/{catalog_name}/{schema_name}/{volume_leaf}/diabetes_treatment_faq.csv\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dc7bcc36-9516-452d-938c-7aca9ae30b2f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Loading the csv file into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2d7435a1-d0fa-4b6c-81bf-cb900803aa33",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>Topic</th><th>Description</th></tr></thead><tbody><tr><td>What is diabetes?</td><td>Diabetes is a chronic condition that affects how the body processes glucose (sugar). It occurs when the body cannot produce enough insulin or the insulin it produces is ineffective in regulating blood sugar. Insulin is a hormone produced by the pancreas that helps glucose enter the cells of the body for energy. Without sufficient insulin, glucose builds up in the bloodstream, leading to high blood sugar levels. Over time, uncontrolled diabetes can cause serious health complications such as heart disease, kidney damage, nerve damage, and vision problems. Proper management and treatment of diabetes are essential to preventing these complications and maintaining a good quality of life. Early detection, lifestyle changes, and medication are key factors in effectively managing the disease.</td></tr><tr><td>What are the different types of diabetes?</td><td>Diabetes is categorized into two main types: Type 1 and Type 2. Type 1 diabetes is an autoimmune condition where the body’s immune system attacks and destroys the insulin-producing cells in the pancreas, leading to little or no insulin production. It typically develops in children or young adults and requires lifelong insulin therapy. Type 2 diabetes, on the other hand, occurs when the body becomes resistant to insulin or does not produce enough insulin to meet the body’s needs. It is more common in adults, particularly those who are overweight, inactive, or have a family history of the disease. While Type 1 is not preventable, Type 2 can often be prevented or delayed through lifestyle changes, including diet and exercise.</td></tr><tr><td>What are the symptoms of diabetes?</td><td>The symptoms of diabetes can vary depending on the type and how long the condition has been present. Common signs include frequent urination, excessive thirst, hunger, and unexplained weight loss. Some people may experience blurred vision, fatigue, and slow-healing wounds. In the case of Type 1 diabetes, symptoms often develop rapidly, while Type 2 diabetes symptoms may be more subtle and develop over time. Because the early symptoms may not always be noticeable, it is important to get regular check-ups, especially if you are at risk for diabetes. Uncontrolled diabetes can lead to serious complications, so timely diagnosis and treatment are essential.</td></tr><tr><td>How is diabetes diagnosed?</td><td>Diabetes is diagnosed through various blood tests. The fasting blood glucose test measures blood sugar levels after an overnight fast, while the oral glucose tolerance test checks how well the body processes sugar after consuming a sugary drink. The HbA1c test, which reflects the average blood sugar levels over the past 2-3 months, is also commonly used to diagnose and monitor diabetes. An HbA1c level of 6.5% or higher is typically indicative of diabetes. A diagnosis may also involve checking for other conditions associated with diabetes, such as high blood pressure or cholesterol imbalances. Early detection allows for better management and prevention of complications.</td></tr><tr><td>What is the role of insulin in diabetes?</td><td>Insulin is a hormone produced by the pancreas that helps regulate blood sugar levels by allowing glucose to enter cells for energy. In people with diabetes, either the body does not produce enough insulin (Type 1 diabetes) or the body’s cells do not respond effectively to insulin (Type 2 diabetes). As a result, glucose accumulates in the bloodstream, leading to high blood sugar. Insulin therapy, typically in the form of injections or an insulin pump, helps to lower blood sugar levels and mimic the body’s natural insulin production. Insulin is a crucial part of managing diabetes, particularly for those with Type 1, and can also be used in Type 2 when lifestyle changes and oral medications are not sufficient.</td></tr><tr><td>What are the treatment options for type 1 diabetes?</td><td>For people with Type 1 diabetes, treatment primarily involves lifelong insulin therapy to manage blood sugar levels. Insulin can be administered through injections or via an insulin pump. In addition to insulin, individuals with Type 1 diabetes must closely monitor their blood sugar levels throughout the day, maintain a healthy diet, and engage in regular physical activity to help manage their condition. People with Type 1 diabetes also need to be vigilant about potential complications, such as diabetic ketoacidosis, and should regularly consult with their healthcare providers to adjust their treatment plan as needed.</td></tr><tr><td>What are the treatment options for type 2 diabetes?</td><td>For Type 2 diabetes, treatment typically starts with lifestyle modifications such as a balanced diet, regular exercise, and weight management. If lifestyle changes are not sufficient, oral medications such as metformin may be prescribed to help regulate blood sugar levels. In some cases, individuals with Type 2 diabetes may require insulin therapy or other injectable medications to improve insulin sensitivity. For those with severe Type 2 diabetes or obesity, bariatric surgery may be considered to help improve blood sugar control. The goal of treatment is to achieve normal blood sugar levels and prevent complications such as heart disease, kidney damage, or nerve damage.</td></tr><tr><td>How can I manage my blood sugar levels?</td><td>Managing blood sugar levels is essential for diabetes control. The key factors in blood sugar management include regular monitoring, taking prescribed medications, following a healthy diet, exercising regularly, and managing stress. Monitoring your blood sugar levels allows you to understand how food, exercise, and medications affect your glucose. A balanced diet rich in fiber, lean proteins, and healthy fats can help regulate blood sugar. Exercise increases insulin sensitivity, which helps control blood sugar levels. Stress management techniques, such as yoga and relaxation exercises, are also important for maintaining stable blood sugar. Regular doctor visits are essential to adjust treatment plans as needed.</td></tr><tr><td>What is a healthy diet for someone with diabetes?</td><td>A healthy diet for people with diabetes focuses on foods that help regulate blood sugar levels and promote overall health. This includes consuming whole grains, vegetables, lean proteins, and healthy fats while limiting foods with a high glycemic index, such as refined sugars and processed foods. Eating smaller, more frequent meals can also help maintain steady blood sugar levels throughout the day. Carbohydrate counting is a common practice for those with diabetes, as carbohydrates have a direct impact on blood sugar. It is important to work with a dietitian to develop a meal plan that meets individual needs and preferences while promoting blood sugar control.</td></tr><tr><td>How often should I check my blood sugar levels?</td><td>Blood sugar monitoring is essential for people with diabetes to understand how their body responds to different foods, activities, and medications. The frequency of testing depends on the type of diabetes and treatment plan. For individuals with Type 1 diabetes or those on insulin, blood sugar may need to be tested multiple times per day, including before and after meals or exercise. For Type 2 diabetes, the frequency of testing may vary based on medication use and blood sugar control. A healthcare provider can provide personalized recommendations for how often to check blood sugar levels, ensuring that levels remain within the target range to prevent complications.</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "What is diabetes?",
         "Diabetes is a chronic condition that affects how the body processes glucose (sugar). It occurs when the body cannot produce enough insulin or the insulin it produces is ineffective in regulating blood sugar. Insulin is a hormone produced by the pancreas that helps glucose enter the cells of the body for energy. Without sufficient insulin, glucose builds up in the bloodstream, leading to high blood sugar levels. Over time, uncontrolled diabetes can cause serious health complications such as heart disease, kidney damage, nerve damage, and vision problems. Proper management and treatment of diabetes are essential to preventing these complications and maintaining a good quality of life. Early detection, lifestyle changes, and medication are key factors in effectively managing the disease."
        ],
        [
         "What are the different types of diabetes?",
         "Diabetes is categorized into two main types: Type 1 and Type 2. Type 1 diabetes is an autoimmune condition where the body’s immune system attacks and destroys the insulin-producing cells in the pancreas, leading to little or no insulin production. It typically develops in children or young adults and requires lifelong insulin therapy. Type 2 diabetes, on the other hand, occurs when the body becomes resistant to insulin or does not produce enough insulin to meet the body’s needs. It is more common in adults, particularly those who are overweight, inactive, or have a family history of the disease. While Type 1 is not preventable, Type 2 can often be prevented or delayed through lifestyle changes, including diet and exercise."
        ],
        [
         "What are the symptoms of diabetes?",
         "The symptoms of diabetes can vary depending on the type and how long the condition has been present. Common signs include frequent urination, excessive thirst, hunger, and unexplained weight loss. Some people may experience blurred vision, fatigue, and slow-healing wounds. In the case of Type 1 diabetes, symptoms often develop rapidly, while Type 2 diabetes symptoms may be more subtle and develop over time. Because the early symptoms may not always be noticeable, it is important to get regular check-ups, especially if you are at risk for diabetes. Uncontrolled diabetes can lead to serious complications, so timely diagnosis and treatment are essential."
        ],
        [
         "How is diabetes diagnosed?",
         "Diabetes is diagnosed through various blood tests. The fasting blood glucose test measures blood sugar levels after an overnight fast, while the oral glucose tolerance test checks how well the body processes sugar after consuming a sugary drink. The HbA1c test, which reflects the average blood sugar levels over the past 2-3 months, is also commonly used to diagnose and monitor diabetes. An HbA1c level of 6.5% or higher is typically indicative of diabetes. A diagnosis may also involve checking for other conditions associated with diabetes, such as high blood pressure or cholesterol imbalances. Early detection allows for better management and prevention of complications."
        ],
        [
         "What is the role of insulin in diabetes?",
         "Insulin is a hormone produced by the pancreas that helps regulate blood sugar levels by allowing glucose to enter cells for energy. In people with diabetes, either the body does not produce enough insulin (Type 1 diabetes) or the body’s cells do not respond effectively to insulin (Type 2 diabetes). As a result, glucose accumulates in the bloodstream, leading to high blood sugar. Insulin therapy, typically in the form of injections or an insulin pump, helps to lower blood sugar levels and mimic the body’s natural insulin production. Insulin is a crucial part of managing diabetes, particularly for those with Type 1, and can also be used in Type 2 when lifestyle changes and oral medications are not sufficient."
        ],
        [
         "What are the treatment options for type 1 diabetes?",
         "For people with Type 1 diabetes, treatment primarily involves lifelong insulin therapy to manage blood sugar levels. Insulin can be administered through injections or via an insulin pump. In addition to insulin, individuals with Type 1 diabetes must closely monitor their blood sugar levels throughout the day, maintain a healthy diet, and engage in regular physical activity to help manage their condition. People with Type 1 diabetes also need to be vigilant about potential complications, such as diabetic ketoacidosis, and should regularly consult with their healthcare providers to adjust their treatment plan as needed."
        ],
        [
         "What are the treatment options for type 2 diabetes?",
         "For Type 2 diabetes, treatment typically starts with lifestyle modifications such as a balanced diet, regular exercise, and weight management. If lifestyle changes are not sufficient, oral medications such as metformin may be prescribed to help regulate blood sugar levels. In some cases, individuals with Type 2 diabetes may require insulin therapy or other injectable medications to improve insulin sensitivity. For those with severe Type 2 diabetes or obesity, bariatric surgery may be considered to help improve blood sugar control. The goal of treatment is to achieve normal blood sugar levels and prevent complications such as heart disease, kidney damage, or nerve damage."
        ],
        [
         "How can I manage my blood sugar levels?",
         "Managing blood sugar levels is essential for diabetes control. The key factors in blood sugar management include regular monitoring, taking prescribed medications, following a healthy diet, exercising regularly, and managing stress. Monitoring your blood sugar levels allows you to understand how food, exercise, and medications affect your glucose. A balanced diet rich in fiber, lean proteins, and healthy fats can help regulate blood sugar. Exercise increases insulin sensitivity, which helps control blood sugar levels. Stress management techniques, such as yoga and relaxation exercises, are also important for maintaining stable blood sugar. Regular doctor visits are essential to adjust treatment plans as needed."
        ],
        [
         "What is a healthy diet for someone with diabetes?",
         "A healthy diet for people with diabetes focuses on foods that help regulate blood sugar levels and promote overall health. This includes consuming whole grains, vegetables, lean proteins, and healthy fats while limiting foods with a high glycemic index, such as refined sugars and processed foods. Eating smaller, more frequent meals can also help maintain steady blood sugar levels throughout the day. Carbohydrate counting is a common practice for those with diabetes, as carbohydrates have a direct impact on blood sugar. It is important to work with a dietitian to develop a meal plan that meets individual needs and preferences while promoting blood sugar control."
        ],
        [
         "How often should I check my blood sugar levels?",
         "Blood sugar monitoring is essential for people with diabetes to understand how their body responds to different foods, activities, and medications. The frequency of testing depends on the type of diabetes and treatment plan. For individuals with Type 1 diabetes or those on insulin, blood sugar may need to be tested multiple times per day, including before and after meals or exercise. For Type 2 diabetes, the frequency of testing may vary based on medication use and blood sugar control. A healthcare provider can provide personalized recommendations for how often to check blood sugar levels, ensuring that levels remain within the target range to prevent complications."
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "Topic",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Description",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- Topic: string (nullable = true)\n |-- Description: string (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import *\n",
    "\n",
    "df = spark.read.csv(data_path, header=True)\n",
    "display(df.limit(10))\n",
    "df.printSchema()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "864afa96-bc1a-4c0d-8cb3-570ca111b38e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Installing the openai SDK in our python kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6bbc7cf2-807d-496d-909b-432c0950af67",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Libraries are installed on the cluster via Terraform.\n",
    "# - openai\n",
    "# - databricks-vectorsearch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4ab5d198-79b2-4977-8bb9-0582ccaacdcb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Restarting our python kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d8b4bb5f-7954-445f-b1d0-a62f58db4cce",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# No restart needed when cluster libraries are pre-installed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "621bf64f-8d20-48a8-9f7b-8b5bfa943b44",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Creating an Azure OpenAI Client\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b9aee125-897a-49c7-8f9a-4bf0f6eea997",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from openai import AzureOpenAI\n",
    "import json\n",
    "\n",
    "openai_endpoint = dbutils.secrets.get(\"aoai-scope\", \"openai-api-base\")\n",
    "openai_key = dbutils.secrets.get(\"aoai-scope\", \"openai-api-key\")\n",
    "openai_api_version = dbutils.secrets.get(\"aoai-scope\", \"openai-api-version\")\n",
    "deployment_name = dbutils.secrets.get(\"aoai-scope\", \"openai-deployment-name\")\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    api_key=openai_key,\n",
    "    api_version=openai_api_version,\n",
    "    azure_endpoint=openai_endpoint,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c9e7a6f4-ca0a-4616-b89c-94b51abe3fff",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Saving the updated/new dataframe into ADLS as parquet storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "afd8fc9d-9f05-408a-9bab-b6c1699d7e62",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Save the updated DataFrame as a Parquet file or table\n",
    "parquet_path = f\"dbfs:/Volumes/{catalog_name}/{schema_name}/raw/diabetes_faq.parquet\"\n",
    "df.write.mode(\"overwrite\").parquet(parquet_path)\n",
    "df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(table_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7c48aa08-5c09-497e-a843-8e3d8b165d34",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Installing the databricks vectorsearch SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bb5392bb-6e57-49c4-b8a3-3866532db618",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Libraries are installed on the cluster via Terraform.\n",
    "# - openai\n",
    "# - databricks-vectorsearch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "57293626-799d-418f-a6b4-312f9dbc2b7d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Restarting our python environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6668150e-dd1b-4d55-b2da-59d04817afbc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# No restart needed when cluster libraries are pre-installed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d440ba2a-970a-41aa-b9ea-df1df8e59c82",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Enabling Change Data Feed on Our Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8b15f107-4087-4352-911f-d360e7c8a412",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Enable change data feed for the existing Delta table\n",
    "spark.sql(\n",
    "    f\"\"\"\n",
    "ALTER TABLE {table_name}\n",
    "SET TBLPROPERTIES (delta.enableChangeDataFeed = true)\n",
    "    \"\"\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4bf4cc35-92a1-40fc-bcd5-c56775a06836",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Developing the Cluster managed Vector index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d5e5e12e-2537-46b2-876d-e250da67f548",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NOTICE] Using a notebook authentication token. Recommended for development only. For improved performance, please use Service Principal based authentication. To disable this message, pass disable_notice=True.\n✅ Using endpoint: vector_search_endpoint\n[20:10:12] endpoint=vector_search_endpoint state=ONLINE\nℹ️ Index already exists.\nℹ️ index.sync() triggered.\n[20:10:14] index_state=ONLINE_UPDATING_PIPELINE_RESOURCES ready=True\n\n✅ Index READY\n{'detailed_state': 'ONLINE_UPDATING_PIPELINE_RESOURCES', 'message': 'Index is currently online, pipeline update is pending setup of pipeline resources. Check latest status: https://adb-7405608176797015.15.azuredatabricks.net/explore/data/adb_genai_super_locust/rag/diabetes_faq_index', 'indexed_row_count': 10, 'triggered_update_status': {'last_processed_commit_version': 14, 'last_processed_commit_timestamp': '2025-12-31T20:09:02Z'}, 'ready': True, 'index_url': 'adb-7405608176797015.15.azuredatabricks.net/api/2.0/vector-search/indexes/adb_genai_super_locust.rag.diabetes_faq_index'}\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Databricks Vector Search: quota-safe endpoint reuse + index\n",
    "# ============================================================\n",
    "\n",
    "from databricks.vector_search.client import VectorSearchClient\n",
    "import time\n",
    "\n",
    "vector_client = VectorSearchClient()  # optionally: VectorSearchClient(disable_notice=True)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Assumes these are defined earlier in your notebook:\n",
    "#   table_name (e.g. \"catalog.schema.table\")\n",
    "#   index_name (e.g. \"catalog.schema.index\")\n",
    "# Optional:\n",
    "#   endpoint_name (preferred endpoint)\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "preferred_endpoint_name = globals().get(\"endpoint_name\", \"vector_search_endpoint\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Endpoint helpers\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "def list_endpoints_safe(client):\n",
    "    if not hasattr(client, \"list_endpoints\"):\n",
    "        return []\n",
    "    eps = client.list_endpoints()\n",
    "    if isinstance(eps, dict):\n",
    "        eps = eps.get(\"endpoints\") or eps.get(\"vector_search_endpoints\") or []\n",
    "    return eps or []\n",
    "\n",
    "def get_endpoint_info_safe(client, name):\n",
    "    if hasattr(client, \"get_endpoint\"):\n",
    "        try:\n",
    "            return client.get_endpoint(name)\n",
    "        except Exception:\n",
    "            return None\n",
    "    # fallback to list\n",
    "    for ep in list_endpoints_safe(client):\n",
    "        if isinstance(ep, dict) and ep.get(\"name\") == name:\n",
    "            return ep\n",
    "    return None\n",
    "\n",
    "def pick_endpoint_name(client, preferred):\n",
    "    \"\"\"\n",
    "    Return an endpoint to use:\n",
    "    1) preferred if it exists\n",
    "    2) otherwise the first existing endpoint\n",
    "    3) otherwise None\n",
    "    \"\"\"\n",
    "    if get_endpoint_info_safe(client, preferred) is not None:\n",
    "        return preferred\n",
    "\n",
    "    eps = list_endpoints_safe(client)\n",
    "    if eps:\n",
    "        first = eps[0]\n",
    "        return first.get(\"name\") if isinstance(first, dict) else first\n",
    "\n",
    "    return None\n",
    "\n",
    "def ensure_endpoint(client, preferred_name):\n",
    "    \"\"\"\n",
    "    Ensure we have an endpoint name to use, respecting quota.\n",
    "    If quota exceeded, reuse an existing endpoint.\n",
    "    \"\"\"\n",
    "    # If it already exists, reuse it\n",
    "    existing = pick_endpoint_name(client, preferred_name)\n",
    "    if existing:\n",
    "        return existing\n",
    "\n",
    "    # Otherwise attempt to create it\n",
    "    try:\n",
    "        client.create_endpoint(name=preferred_name, endpoint_type=\"STANDARD\")\n",
    "        return preferred_name\n",
    "    except Exception as exc:\n",
    "        msg = str(exc)\n",
    "        # Quota hit: reuse any existing endpoint\n",
    "        if \"QUOTA_EXCEEDED\" in msg or \"Maximum number of vector search endpoints\" in msg:\n",
    "            existing = pick_endpoint_name(client, preferred_name)\n",
    "            if existing:\n",
    "                return existing\n",
    "        # Anything else is real\n",
    "        raise\n",
    "\n",
    "def wait_for_endpoint_online(client, name, timeout_s=1800, poll_s=15):\n",
    "    deadline = time.time() + timeout_s\n",
    "    last = None\n",
    "    while time.time() < deadline:\n",
    "        info = get_endpoint_info_safe(client, name)\n",
    "        last = info\n",
    "        state = None\n",
    "        if isinstance(info, dict):\n",
    "            st = info.get(\"endpoint_status\") or info.get(\"status\") or {}\n",
    "            state = st.get(\"state\") if isinstance(st, dict) else st\n",
    "        print(f\"[{time.strftime('%H:%M:%S')}] endpoint={name} state={state}\")\n",
    "        if state in (\"ONLINE\", \"READY\"):\n",
    "            return info\n",
    "        if state in (\"FAILED\", \"ERROR\"):\n",
    "            raise RuntimeError(f\"Endpoint failure: {info}\")\n",
    "        time.sleep(poll_s)\n",
    "    raise TimeoutError(f\"Endpoint not online after {timeout_s}s. Last: {last}\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Index helpers (matches your describe() payload)\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "def wait_for_index_ready(index, timeout_s=1800, poll_s=15):\n",
    "    deadline = time.time() + timeout_s\n",
    "    last = None\n",
    "    while time.time() < deadline:\n",
    "        info = index.describe()\n",
    "        last = info\n",
    "        status = info.get(\"status\") or {}\n",
    "        detailed_state = status.get(\"detailed_state\")\n",
    "        ready = status.get(\"ready\")\n",
    "        print(f\"[{time.strftime('%H:%M:%S')}] index_state={detailed_state} ready={ready}\")\n",
    "        if ready is True:\n",
    "            return info\n",
    "        if isinstance(detailed_state, str) and (\"FAILED\" in detailed_state or \"ERROR\" in detailed_state):\n",
    "            raise RuntimeError(f\"Index failure: {info}\")\n",
    "        time.sleep(poll_s)\n",
    "    raise TimeoutError(f\"Index not ready after {timeout_s}s. Last: {last}\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 1) Get endpoint without exceeding quota\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "endpoint_name = ensure_endpoint(vector_client, preferred_endpoint_name)\n",
    "print(f\"✅ Using endpoint: {endpoint_name}\")\n",
    "\n",
    "# 2) Wait for endpoint\n",
    "wait_for_endpoint_online(vector_client, endpoint_name)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 3) Get or create index\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "try:\n",
    "    index = vector_client.get_index(endpoint_name, index_name)\n",
    "    print(\"ℹ️ Index already exists.\")\n",
    "except Exception:\n",
    "    print(\"ℹ️ Creating index...\")\n",
    "    index = vector_client.create_delta_sync_index(\n",
    "        endpoint_name=endpoint_name,\n",
    "        source_table_name=table_name,\n",
    "        index_name=index_name,\n",
    "        pipeline_type=\"TRIGGERED\",\n",
    "        primary_key=\"Topic\",\n",
    "        embedding_source_column=\"Description\",\n",
    "        embedding_model_endpoint_name=\"databricks-gte-large-en\",\n",
    "    )\n",
    "\n",
    "# 4) Trigger sync (optional, safe)\n",
    "try:\n",
    "    index.sync()\n",
    "    print(\"ℹ️ index.sync() triggered.\")\n",
    "except Exception as exc:\n",
    "    if \"not supported\" not in str(exc).lower():\n",
    "        raise\n",
    "\n",
    "# 5) Wait for readiness\n",
    "final_info = wait_for_index_ready(index)\n",
    "\n",
    "print(\"\\n✅ Index READY\")\n",
    "print(final_info[\"status\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7e47fc11-bf75-462f-ba71-f9dea08a8a96",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Triggering our Vector Index - Information Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c8b6fcc8-199a-43fa-afb9-710394d01ac7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NOTICE] Using a notebook authentication token. Recommended for development only. For improved performance, please use Service Principal based authentication. To disable this message, pass disable_notice=True.\n['What is diabetes?', 'Diabetes is a chronic condition that affects how the body processes glucose (sugar). It occurs when the body cannot produce enough insulin or the insulin it produces is ineffective in regulating blood sugar. Insulin is a hormone produced by the pancreas that helps glucose enter the cells of the body for energy. Without sufficient insulin, glucose builds up in the bloodstream, leading to high blood sugar levels. Over time, uncontrolled diabetes can cause serious health complications such as heart disease, kidney damage, nerve damage, and vision problems. Proper management and treatment of diabetes are essential to preventing these complications and maintaining a good quality of life. Early detection, lifestyle changes, and medication are key factors in effectively managing the disease.', 0.0041667074]\n"
     ]
    }
   ],
   "source": [
    "user_question = \"what is diabetes?\"\n",
    "\n",
    "results_dict = index.similarity_search(\n",
    "    query_text=user_question,\n",
    "    columns=[\"Topic\", \"Description\"],\n",
    "    num_results=1,\n",
    ")\n",
    "\n",
    "content = str(results_dict[\"result\"][\"data_array\"][0])\n",
    "print(content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dc1db6ca-dd52-45e6-94bd-9073997c1c7a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Developing the Generation Component of our RAG architecture\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3c4262ff-7e91-44e1-964e-d99fce2343c6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diabetes is a long-term condition that affects how the body regulates blood sugar (glucose). It occurs when the body doesn’t produce enough insulin or when the insulin it makes doesn’t work properly. Insulin is a hormone made by the pancreas that allows glucose from food to enter cells and be used for energy. When this process doesn’t work as it should, glucose builds up in the blood, leading to high blood sugar levels.  \n\nIf diabetes isn’t well managed, it can lead to serious complications such as heart disease, kidney damage, nerve problems, and vision loss. Effective management involves early detection, healthy lifestyle choices, regular monitoring, and in some cases, medication or insulin therapy.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/databricks.mlflow.trace": "\"tr-06d8bf357e6b0ca415e312e51b806317\"",
      "text/plain": [
       "Trace(trace_id=tr-06d8bf357e6b0ca415e312e51b806317)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gpt_response = client.chat.completions.create(\n",
    "    model=deployment_name,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant. You will be passed the user query and the supporting knowledge that can be used to answer the user_query\"},\n",
    "        {\"role\": \"user\", \"content\": f\"user query : {user_question} and supporting knowledge: {content}\"},\n",
    "    ],\n",
    ")\n",
    "print(gpt_response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e5dcdb55-2157-48c5-9fd7-1db31a68564b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Developing the RAG model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4846c36e-0d28-4590-99db-62dd88d0d4d4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/databricks/python/lib/python3.12/site-packages/mlflow/pyfunc/utils/data_validation.py:155: FutureWarning: Model's `predict` method contains invalid parameters: {'data'}. Only the following parameter names are allowed: context, model_input, and params. Note that invalid parameters will no longer be permitted in future versions.\n  param_names = _check_func_signature(func, \"predict\")\n/databricks/python/lib/python3.12/site-packages/mlflow/pyfunc/utils/data_validation.py:186: UserWarning: \u001B[33mAdd type hints to the `predict` method to enable data validation and automatic signature inference during model logging. Check https://mlflow.org/docs/latest/model/python_model.html#type-hint-usage-in-pythonmodel for more details.\u001B[0m\n  color_warning(\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "from mlflow import pyfunc\n",
    "\n",
    "class RAGModel(pyfunc.PythonModel):\n",
    "    def __init__(self, vector_index, openai_client, deployment_name):\n",
    "        self.vector_index = vector_index\n",
    "        self.openai_client = openai_client\n",
    "        self.deployment_name = deployment_name\n",
    "\n",
    "    def retrieve(self, query):\n",
    "        results_dict = self.vector_index.similarity_search(\n",
    "            query_text=query,\n",
    "            columns=[\"Topic\", \"Description\"],\n",
    "            num_results=1,\n",
    "        )\n",
    "        return str(results_dict[\"result\"][\"data_array\"][0])\n",
    "\n",
    "    def chatCompletionsAPI(self, user_query, supporting_knowledge):\n",
    "        response = self.openai_client.chat.completions.create(\n",
    "            model=self.deployment_name,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant. You will be passed the user query and the supporting knowledge that can be used to answer the user_query\"},\n",
    "                {\"role\": \"user\", \"content\": f\"user query : {user_query} and supporting knowledge: {supporting_knowledge}\"},\n",
    "            ],\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "\n",
    "    def predict(self, context, data):\n",
    "        query = data[\"query\"].iloc[0]\n",
    "        supporting_knowledge = self.retrieve(query)\n",
    "        return self.chatCompletionsAPI(query, supporting_knowledge)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4c09fa66-69ff-407c-8112-e7d0e5cd0190",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Saving our Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "046368a3-d146-46b3-a959-698b7024f5b8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "test_model = RAGModel(vector_index=index, openai_client=client, deployment_name=deployment_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8ea427f6-682d-489c-a58d-4dee89f99f20",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mIllegalArgumentException\u001B[0m                  Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-5844878010764383>, line 2\u001B[0m\n",
       "\u001B[1;32m      1\u001B[0m os\u001B[38;5;241m.\u001B[39menviron[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDATABRICKS_HOST\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhttps://eastus2-c3.azuredatabricks.net\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
       "\u001B[0;32m----> 2\u001B[0m os\u001B[38;5;241m.\u001B[39menviron[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDATABRICKS_TOKEN\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m dbutils\u001B[38;5;241m.\u001B[39msecrets\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mYOUR_SCOPE\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mYOUR_PAT_SECRET\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
       "\n",
       "File \u001B[0;32m/databricks/python_shell/lib/dbruntime/dbutils.py:376\u001B[0m, in \u001B[0;36mDBUtils.SecretsHandler.get\u001B[0;34m(self, scope, catalog, schema, key, *posArgs)\u001B[0m\n",
       "\u001B[1;32m    373\u001B[0m     scope \u001B[38;5;241m=\u001B[39m argsToPass[\u001B[38;5;241m0\u001B[39m]\n",
       "\u001B[1;32m    374\u001B[0m     key \u001B[38;5;241m=\u001B[39m argsToPass[\u001B[38;5;241m1\u001B[39m]\n",
       "\u001B[1;32m    375\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mentry_point\u001B[38;5;241m.\u001B[39mgetDbutils()\u001B[38;5;241m.\u001B[39mpreview()\u001B[38;5;241m.\u001B[39msecret(\n",
       "\u001B[0;32m--> 376\u001B[0m     )\u001B[38;5;241m.\u001B[39mget(  \u001B[38;5;66;03m# type: ignore[attr-defined]\u001B[39;00m\n",
       "\u001B[1;32m    377\u001B[0m         scope, key)\n",
       "\u001B[1;32m    378\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
       "\u001B[1;32m    379\u001B[0m     catalog \u001B[38;5;241m=\u001B[39m argsToPass[\u001B[38;5;241m0\u001B[39m]\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.9-src.zip/py4j/java_gateway.py:1362\u001B[0m, in \u001B[0;36mJavaMember.__call__\u001B[0;34m(self, *args)\u001B[0m\n",
       "\u001B[1;32m   1356\u001B[0m command \u001B[38;5;241m=\u001B[39m proto\u001B[38;5;241m.\u001B[39mCALL_COMMAND_NAME \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1357\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommand_header \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1358\u001B[0m     args_command \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1359\u001B[0m     proto\u001B[38;5;241m.\u001B[39mEND_COMMAND_PART\n",
       "\u001B[1;32m   1361\u001B[0m answer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client\u001B[38;5;241m.\u001B[39msend_command(command)\n",
       "\u001B[0;32m-> 1362\u001B[0m return_value \u001B[38;5;241m=\u001B[39m get_return_value(\n",
       "\u001B[1;32m   1363\u001B[0m     answer, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtarget_id, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mname)\n",
       "\u001B[1;32m   1365\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m temp_arg \u001B[38;5;129;01min\u001B[39;00m temp_args:\n",
       "\u001B[1;32m   1366\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(temp_arg, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_detach\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/pyspark/errors/exceptions/captured.py:310\u001B[0m, in \u001B[0;36mcapture_sql_exception.<locals>.deco\u001B[0;34m(*a, **kw)\u001B[0m\n",
       "\u001B[1;32m    306\u001B[0m converted \u001B[38;5;241m=\u001B[39m convert_exception(e\u001B[38;5;241m.\u001B[39mjava_exception)\n",
       "\u001B[1;32m    307\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(converted, UnknownException):\n",
       "\u001B[1;32m    308\u001B[0m     \u001B[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001B[39;00m\n",
       "\u001B[1;32m    309\u001B[0m     \u001B[38;5;66;03m# JVM exception message.\u001B[39;00m\n",
       "\u001B[0;32m--> 310\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m converted \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
       "\u001B[1;32m    311\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
       "\u001B[1;32m    312\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m\n",
       "\n",
       "\u001B[0;31mIllegalArgumentException\u001B[0m: Secret does not exist with scope: YOUR_SCOPE and key: YOUR_PAT_SECRET"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": {
        "ename": "IllegalArgumentException",
        "evalue": "Secret does not exist with scope: YOUR_SCOPE and key: YOUR_PAT_SECRET"
       },
       "metadata": {
        "errorSummary": "<span class='ansi-red-fg'>IllegalArgumentException</span>: Secret does not exist with scope: YOUR_SCOPE and key: YOUR_PAT_SECRET"
       },
       "removedWidgets": [],
       "sqlProps": {
        "breakingChangeInfo": null,
        "errorClass": null,
        "pysparkCallSite": "",
        "pysparkFragment": "",
        "pysparkSummary": "",
        "sqlState": null,
        "stackTrace": null,
        "startIndex": null,
        "stopIndex": null
       },
       "stackFrames": [
        "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
        "\u001B[0;31mIllegalArgumentException\u001B[0m                  Traceback (most recent call last)",
        "File \u001B[0;32m<command-5844878010764383>, line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m os\u001B[38;5;241m.\u001B[39menviron[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDATABRICKS_HOST\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhttps://eastus2-c3.azuredatabricks.net\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m----> 2\u001B[0m os\u001B[38;5;241m.\u001B[39menviron[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDATABRICKS_TOKEN\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m dbutils\u001B[38;5;241m.\u001B[39msecrets\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mYOUR_SCOPE\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mYOUR_PAT_SECRET\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
        "File \u001B[0;32m/databricks/python_shell/lib/dbruntime/dbutils.py:376\u001B[0m, in \u001B[0;36mDBUtils.SecretsHandler.get\u001B[0;34m(self, scope, catalog, schema, key, *posArgs)\u001B[0m\n\u001B[1;32m    373\u001B[0m     scope \u001B[38;5;241m=\u001B[39m argsToPass[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m    374\u001B[0m     key \u001B[38;5;241m=\u001B[39m argsToPass[\u001B[38;5;241m1\u001B[39m]\n\u001B[1;32m    375\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mentry_point\u001B[38;5;241m.\u001B[39mgetDbutils()\u001B[38;5;241m.\u001B[39mpreview()\u001B[38;5;241m.\u001B[39msecret(\n\u001B[0;32m--> 376\u001B[0m     )\u001B[38;5;241m.\u001B[39mget(  \u001B[38;5;66;03m# type: ignore[attr-defined]\u001B[39;00m\n\u001B[1;32m    377\u001B[0m         scope, key)\n\u001B[1;32m    378\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    379\u001B[0m     catalog \u001B[38;5;241m=\u001B[39m argsToPass[\u001B[38;5;241m0\u001B[39m]\n",
        "File \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.9-src.zip/py4j/java_gateway.py:1362\u001B[0m, in \u001B[0;36mJavaMember.__call__\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m   1356\u001B[0m command \u001B[38;5;241m=\u001B[39m proto\u001B[38;5;241m.\u001B[39mCALL_COMMAND_NAME \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1357\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommand_header \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1358\u001B[0m     args_command \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1359\u001B[0m     proto\u001B[38;5;241m.\u001B[39mEND_COMMAND_PART\n\u001B[1;32m   1361\u001B[0m answer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client\u001B[38;5;241m.\u001B[39msend_command(command)\n\u001B[0;32m-> 1362\u001B[0m return_value \u001B[38;5;241m=\u001B[39m get_return_value(\n\u001B[1;32m   1363\u001B[0m     answer, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtarget_id, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mname)\n\u001B[1;32m   1365\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m temp_arg \u001B[38;5;129;01min\u001B[39;00m temp_args:\n\u001B[1;32m   1366\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(temp_arg, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_detach\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n",
        "File \u001B[0;32m/databricks/spark/python/pyspark/errors/exceptions/captured.py:310\u001B[0m, in \u001B[0;36mcapture_sql_exception.<locals>.deco\u001B[0;34m(*a, **kw)\u001B[0m\n\u001B[1;32m    306\u001B[0m converted \u001B[38;5;241m=\u001B[39m convert_exception(e\u001B[38;5;241m.\u001B[39mjava_exception)\n\u001B[1;32m    307\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(converted, UnknownException):\n\u001B[1;32m    308\u001B[0m     \u001B[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001B[39;00m\n\u001B[1;32m    309\u001B[0m     \u001B[38;5;66;03m# JVM exception message.\u001B[39;00m\n\u001B[0;32m--> 310\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m converted \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    311\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    312\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m\n",
        "\u001B[0;31mIllegalArgumentException\u001B[0m: Secret does not exist with scope: YOUR_SCOPE and key: YOUR_PAT_SECRET"
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "os.environ[\"DATABRICKS_HOST\"] = \"https://eastus2-c3.azuredatabricks.net\"\n",
    "os.environ[\"DATABRICKS_TOKEN\"] = dbutils.secrets.get(\"YOUR_SCOPE\", \"YOUR_PAT_SECRET\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9bd6997d-729f-47bd-9003-75e942b9ea18",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ AOAI env vars present: True True True\n✅ DBX env vars present: False False\n✅ Wrote model script: /tmp/rag_model_from_code.py\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\uD83D\uDD17 View Logged Model at: https://adb-7405608176797015.15.azuredatabricks.net/ml/experiments/2016950050110299/models/m-0a6d8f405dbe43abacae10002d9aeba5?o=7405608176797015\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-5475092539584904>, line 153\u001B[0m\n",
       "\u001B[1;32m    150\u001B[0m input_example \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame([{\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mquery\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mwhat is diabetes?\u001B[39m\u001B[38;5;124m\"\u001B[39m}])\n",
       "\u001B[1;32m    152\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m mlflow\u001B[38;5;241m.\u001B[39mstart_run() \u001B[38;5;28;01mas\u001B[39;00m run:\n",
       "\u001B[0;32m--> 153\u001B[0m     model_info \u001B[38;5;241m=\u001B[39m mlflow\u001B[38;5;241m.\u001B[39mpyfunc\u001B[38;5;241m.\u001B[39mlog_model(\n",
       "\u001B[1;32m    154\u001B[0m         python_model\u001B[38;5;241m=\u001B[39mscript_path,\n",
       "\u001B[1;32m    155\u001B[0m         name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrag_model\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n",
       "\u001B[1;32m    156\u001B[0m         input_example\u001B[38;5;241m=\u001B[39minput_example,\n",
       "\u001B[1;32m    157\u001B[0m         pip_requirements\u001B[38;5;241m=\u001B[39m[\n",
       "\u001B[1;32m    158\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmlflow\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n",
       "\u001B[1;32m    159\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpandas\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n",
       "\u001B[1;32m    160\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mopenai\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n",
       "\u001B[1;32m    161\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdatabricks-vectorsearch\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n",
       "\u001B[1;32m    162\u001B[0m         ],\n",
       "\u001B[1;32m    163\u001B[0m     )\n",
       "\u001B[1;32m    164\u001B[0m     model_uri \u001B[38;5;241m=\u001B[39m model_info\u001B[38;5;241m.\u001B[39mmodel_uri\n",
       "\u001B[1;32m    165\u001B[0m     mlflow\u001B[38;5;241m.\u001B[39mlog_text(model_uri, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodel_uri.txt\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.12/site-packages/mlflow/tracing/provider.py:435\u001B[0m, in \u001B[0;36mtrace_disabled.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n",
       "\u001B[1;32m    433\u001B[0m disable()\n",
       "\u001B[1;32m    434\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
       "\u001B[0;32m--> 435\u001B[0m     is_func_called, result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m, f(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
       "\u001B[1;32m    436\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n",
       "\u001B[1;32m    437\u001B[0m     enable()\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.12/site-packages/mlflow/pyfunc/__init__.py:3579\u001B[0m, in \u001B[0;36mlog_model\u001B[0;34m(artifact_path, loader_module, data_path, code_paths, infer_code_paths, conda_env, python_model, artifacts, registered_model_name, signature, input_example, await_registration_for, pip_requirements, extra_pip_requirements, metadata, model_config, streamable, resources, auth_policy, prompts, name, params, tags, model_type, step, model_id)\u001B[0m\n",
       "\u001B[1;32m   3347\u001B[0m \u001B[38;5;129m@format_docstring\u001B[39m(LOG_MODEL_PARAM_DOCS\u001B[38;5;241m.\u001B[39mformat(package_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mscikit-learn\u001B[39m\u001B[38;5;124m\"\u001B[39m))\n",
       "\u001B[1;32m   3348\u001B[0m \u001B[38;5;129m@trace_disabled\u001B[39m  \u001B[38;5;66;03m# Suppress traces for internal predict calls while logging model\u001B[39;00m\n",
       "\u001B[1;32m   3349\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mlog_model\u001B[39m(\n",
       "\u001B[0;32m   (...)\u001B[0m\n",
       "\u001B[1;32m   3375\u001B[0m     model_id: Optional[\u001B[38;5;28mstr\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n",
       "\u001B[1;32m   3376\u001B[0m ):\n",
       "\u001B[1;32m   3377\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n",
       "\u001B[1;32m   3378\u001B[0m \u001B[38;5;124;03m    Log a Pyfunc model with custom inference logic and optional data dependencies as an MLflow\u001B[39;00m\n",
       "\u001B[1;32m   3379\u001B[0m \u001B[38;5;124;03m    artifact for the current run.\u001B[39;00m\n",
       "\u001B[0;32m   (...)\u001B[0m\n",
       "\u001B[1;32m   3577\u001B[0m \u001B[38;5;124;03m        metadata of the logged model.\u001B[39;00m\n",
       "\u001B[1;32m   3578\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n",
       "\u001B[0;32m-> 3579\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m Model\u001B[38;5;241m.\u001B[39mlog(\n",
       "\u001B[1;32m   3580\u001B[0m         artifact_path\u001B[38;5;241m=\u001B[39martifact_path,\n",
       "\u001B[1;32m   3581\u001B[0m         name\u001B[38;5;241m=\u001B[39mname,\n",
       "\u001B[1;32m   3582\u001B[0m         flavor\u001B[38;5;241m=\u001B[39mmlflow\u001B[38;5;241m.\u001B[39mpyfunc,\n",
       "\u001B[1;32m   3583\u001B[0m         loader_module\u001B[38;5;241m=\u001B[39mloader_module,\n",
       "\u001B[1;32m   3584\u001B[0m         data_path\u001B[38;5;241m=\u001B[39mdata_path,\n",
       "\u001B[1;32m   3585\u001B[0m         code_paths\u001B[38;5;241m=\u001B[39mcode_paths,\n",
       "\u001B[1;32m   3586\u001B[0m         python_model\u001B[38;5;241m=\u001B[39mpython_model,\n",
       "\u001B[1;32m   3587\u001B[0m         artifacts\u001B[38;5;241m=\u001B[39martifacts,\n",
       "\u001B[1;32m   3588\u001B[0m         conda_env\u001B[38;5;241m=\u001B[39mconda_env,\n",
       "\u001B[1;32m   3589\u001B[0m         registered_model_name\u001B[38;5;241m=\u001B[39mregistered_model_name,\n",
       "\u001B[1;32m   3590\u001B[0m         signature\u001B[38;5;241m=\u001B[39msignature,\n",
       "\u001B[1;32m   3591\u001B[0m         input_example\u001B[38;5;241m=\u001B[39minput_example,\n",
       "\u001B[1;32m   3592\u001B[0m         await_registration_for\u001B[38;5;241m=\u001B[39mawait_registration_for,\n",
       "\u001B[1;32m   3593\u001B[0m         pip_requirements\u001B[38;5;241m=\u001B[39mpip_requirements,\n",
       "\u001B[1;32m   3594\u001B[0m         extra_pip_requirements\u001B[38;5;241m=\u001B[39mextra_pip_requirements,\n",
       "\u001B[1;32m   3595\u001B[0m         metadata\u001B[38;5;241m=\u001B[39mmetadata,\n",
       "\u001B[1;32m   3596\u001B[0m         prompts\u001B[38;5;241m=\u001B[39mprompts,\n",
       "\u001B[1;32m   3597\u001B[0m         model_config\u001B[38;5;241m=\u001B[39mmodel_config,\n",
       "\u001B[1;32m   3598\u001B[0m         streamable\u001B[38;5;241m=\u001B[39mstreamable,\n",
       "\u001B[1;32m   3599\u001B[0m         resources\u001B[38;5;241m=\u001B[39mresources,\n",
       "\u001B[1;32m   3600\u001B[0m         infer_code_paths\u001B[38;5;241m=\u001B[39minfer_code_paths,\n",
       "\u001B[1;32m   3601\u001B[0m         auth_policy\u001B[38;5;241m=\u001B[39mauth_policy,\n",
       "\u001B[1;32m   3602\u001B[0m         params\u001B[38;5;241m=\u001B[39mparams,\n",
       "\u001B[1;32m   3603\u001B[0m         tags\u001B[38;5;241m=\u001B[39mtags,\n",
       "\u001B[1;32m   3604\u001B[0m         model_type\u001B[38;5;241m=\u001B[39mmodel_type,\n",
       "\u001B[1;32m   3605\u001B[0m         step\u001B[38;5;241m=\u001B[39mstep,\n",
       "\u001B[1;32m   3606\u001B[0m         model_id\u001B[38;5;241m=\u001B[39mmodel_id,\n",
       "\u001B[1;32m   3607\u001B[0m     )\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.12/site-packages/mlflow/models/model.py:1207\u001B[0m, in \u001B[0;36mModel.log\u001B[0;34m(cls, artifact_path, flavor, registered_model_name, await_registration_for, metadata, run_id, resources, auth_policy, prompts, name, model_type, params, tags, step, model_id, **kwargs)\u001B[0m\n",
       "\u001B[1;32m   1195\u001B[0m     prompts \u001B[38;5;241m=\u001B[39m [pr\u001B[38;5;241m.\u001B[39muri \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(pr, Prompt) \u001B[38;5;28;01melse\u001B[39;00m pr \u001B[38;5;28;01mfor\u001B[39;00m pr \u001B[38;5;129;01min\u001B[39;00m prompts]\n",
       "\u001B[1;32m   1197\u001B[0m mlflow_model \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mcls\u001B[39m(\n",
       "\u001B[1;32m   1198\u001B[0m     artifact_path\u001B[38;5;241m=\u001B[39mmodel\u001B[38;5;241m.\u001B[39martifact_location,\n",
       "\u001B[1;32m   1199\u001B[0m     model_uuid\u001B[38;5;241m=\u001B[39mmodel\u001B[38;5;241m.\u001B[39mmodel_id,\n",
       "\u001B[0;32m   (...)\u001B[0m\n",
       "\u001B[1;32m   1205\u001B[0m     model_id\u001B[38;5;241m=\u001B[39mmodel\u001B[38;5;241m.\u001B[39mmodel_id,\n",
       "\u001B[1;32m   1206\u001B[0m )\n",
       "\u001B[0;32m-> 1207\u001B[0m flavor\u001B[38;5;241m.\u001B[39msave_model(path\u001B[38;5;241m=\u001B[39mlocal_path, mlflow_model\u001B[38;5;241m=\u001B[39mmlflow_model, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
       "\u001B[1;32m   1208\u001B[0m \u001B[38;5;66;03m# `save_model` calls `load_model` to infer the model requirements, which may result\u001B[39;00m\n",
       "\u001B[1;32m   1209\u001B[0m \u001B[38;5;66;03m# in __pycache__ directories being created in the model directory.\u001B[39;00m\n",
       "\u001B[1;32m   1210\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m pycache \u001B[38;5;129;01min\u001B[39;00m Path(local_path)\u001B[38;5;241m.\u001B[39mrglob(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__pycache__\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.12/site-packages/mlflow/tracing/provider.py:439\u001B[0m, in \u001B[0;36mtrace_disabled.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n",
       "\u001B[1;32m    437\u001B[0m             enable()\n",
       "\u001B[1;32m    438\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n",
       "\u001B[0;32m--> 439\u001B[0m         is_func_called, result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m, f(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
       "\u001B[1;32m    440\u001B[0m \u001B[38;5;66;03m# We should only catch the exception from disable() and enable()\u001B[39;00m\n",
       "\u001B[1;32m    441\u001B[0m \u001B[38;5;66;03m# and let other exceptions propagate.\u001B[39;00m\n",
       "\u001B[1;32m    442\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m MlflowTracingException \u001B[38;5;28;01mas\u001B[39;00m e:\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.12/site-packages/mlflow/pyfunc/__init__.py:3182\u001B[0m, in \u001B[0;36msave_model\u001B[0;34m(path, loader_module, data_path, code_paths, infer_code_paths, conda_env, mlflow_model, python_model, artifacts, signature, input_example, pip_requirements, extra_pip_requirements, metadata, model_config, streamable, resources, auth_policy, **kwargs)\u001B[0m\n",
       "\u001B[1;32m   3180\u001B[0m \u001B[38;5;66;03m# Load context before calling predict to ensure necessary artifacts are available\u001B[39;00m\n",
       "\u001B[1;32m   3181\u001B[0m context \u001B[38;5;241m=\u001B[39m PythonModelContext(artifacts, model_config)\n",
       "\u001B[0;32m-> 3182\u001B[0m model_for_signature_inference\u001B[38;5;241m.\u001B[39mload_context(context)\n",
       "\u001B[1;32m   3183\u001B[0m type_hint_from_example \u001B[38;5;241m=\u001B[39m _is_type_hint_from_example(type_hints\u001B[38;5;241m.\u001B[39minput)\n",
       "\u001B[1;32m   3184\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m type_hint_from_example:\n",
       "\n",
       "File \u001B[0;32m/tmp/rag_model_from_code.py:25\u001B[0m, in \u001B[0;36mRAGModel.load_context\u001B[0;34m(self, context)\u001B[0m\n",
       "\u001B[1;32m     23\u001B[0m aoai_key \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mgetenv(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAZURE_OPENAI_API_KEY\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
       "\u001B[1;32m     24\u001B[0m aoai_version \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mgetenv(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAZURE_OPENAI_API_VERSION\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
       "\u001B[0;32m---> 25\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (aoai_endpoint \u001B[38;5;129;01mand\u001B[39;00m aoai_key \u001B[38;5;129;01mand\u001B[39;00m aoai_version):\n",
       "\u001B[1;32m     26\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMissing AOAI env vars.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
       "\u001B[1;32m     28\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclient \u001B[38;5;241m=\u001B[39m AzureOpenAI(\n",
       "\u001B[1;32m     29\u001B[0m     api_key\u001B[38;5;241m=\u001B[39maoai_key,\n",
       "\u001B[1;32m     30\u001B[0m     api_version\u001B[38;5;241m=\u001B[39maoai_version,\n",
       "\u001B[1;32m     31\u001B[0m     azure_endpoint\u001B[38;5;241m=\u001B[39maoai_endpoint,\n",
       "\u001B[1;32m     32\u001B[0m )\n",
       "\n",
       "\u001B[0;31mRuntimeError\u001B[0m: Missing DATABRICKS_HOST / DATABRICKS_TOKEN. Set these in the Serving endpoint environment variables."
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": {
        "ename": "RuntimeError",
        "evalue": "Missing DATABRICKS_HOST / DATABRICKS_TOKEN. Set these in the Serving endpoint environment variables."
       },
       "metadata": {
        "errorSummary": "<span class='ansi-red-fg'>RuntimeError</span>: Missing DATABRICKS_HOST / DATABRICKS_TOKEN. Set these in the Serving endpoint environment variables."
       },
       "removedWidgets": [],
       "sqlProps": null,
       "stackFrames": [
        "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
        "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
        "File \u001B[0;32m<command-5475092539584904>, line 153\u001B[0m\n\u001B[1;32m    150\u001B[0m input_example \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame([{\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mquery\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mwhat is diabetes?\u001B[39m\u001B[38;5;124m\"\u001B[39m}])\n\u001B[1;32m    152\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m mlflow\u001B[38;5;241m.\u001B[39mstart_run() \u001B[38;5;28;01mas\u001B[39;00m run:\n\u001B[0;32m--> 153\u001B[0m     model_info \u001B[38;5;241m=\u001B[39m mlflow\u001B[38;5;241m.\u001B[39mpyfunc\u001B[38;5;241m.\u001B[39mlog_model(\n\u001B[1;32m    154\u001B[0m         python_model\u001B[38;5;241m=\u001B[39mscript_path,\n\u001B[1;32m    155\u001B[0m         name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrag_model\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    156\u001B[0m         input_example\u001B[38;5;241m=\u001B[39minput_example,\n\u001B[1;32m    157\u001B[0m         pip_requirements\u001B[38;5;241m=\u001B[39m[\n\u001B[1;32m    158\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmlflow\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    159\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpandas\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    160\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mopenai\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    161\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdatabricks-vectorsearch\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    162\u001B[0m         ],\n\u001B[1;32m    163\u001B[0m     )\n\u001B[1;32m    164\u001B[0m     model_uri \u001B[38;5;241m=\u001B[39m model_info\u001B[38;5;241m.\u001B[39mmodel_uri\n\u001B[1;32m    165\u001B[0m     mlflow\u001B[38;5;241m.\u001B[39mlog_text(model_uri, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodel_uri.txt\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
        "File \u001B[0;32m/databricks/python/lib/python3.12/site-packages/mlflow/tracing/provider.py:435\u001B[0m, in \u001B[0;36mtrace_disabled.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    433\u001B[0m disable()\n\u001B[1;32m    434\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 435\u001B[0m     is_func_called, result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m, f(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    436\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m    437\u001B[0m     enable()\n",
        "File \u001B[0;32m/databricks/python/lib/python3.12/site-packages/mlflow/pyfunc/__init__.py:3579\u001B[0m, in \u001B[0;36mlog_model\u001B[0;34m(artifact_path, loader_module, data_path, code_paths, infer_code_paths, conda_env, python_model, artifacts, registered_model_name, signature, input_example, await_registration_for, pip_requirements, extra_pip_requirements, metadata, model_config, streamable, resources, auth_policy, prompts, name, params, tags, model_type, step, model_id)\u001B[0m\n\u001B[1;32m   3347\u001B[0m \u001B[38;5;129m@format_docstring\u001B[39m(LOG_MODEL_PARAM_DOCS\u001B[38;5;241m.\u001B[39mformat(package_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mscikit-learn\u001B[39m\u001B[38;5;124m\"\u001B[39m))\n\u001B[1;32m   3348\u001B[0m \u001B[38;5;129m@trace_disabled\u001B[39m  \u001B[38;5;66;03m# Suppress traces for internal predict calls while logging model\u001B[39;00m\n\u001B[1;32m   3349\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mlog_model\u001B[39m(\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   3375\u001B[0m     model_id: Optional[\u001B[38;5;28mstr\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m   3376\u001B[0m ):\n\u001B[1;32m   3377\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   3378\u001B[0m \u001B[38;5;124;03m    Log a Pyfunc model with custom inference logic and optional data dependencies as an MLflow\u001B[39;00m\n\u001B[1;32m   3379\u001B[0m \u001B[38;5;124;03m    artifact for the current run.\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   3577\u001B[0m \u001B[38;5;124;03m        metadata of the logged model.\u001B[39;00m\n\u001B[1;32m   3578\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m-> 3579\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m Model\u001B[38;5;241m.\u001B[39mlog(\n\u001B[1;32m   3580\u001B[0m         artifact_path\u001B[38;5;241m=\u001B[39martifact_path,\n\u001B[1;32m   3581\u001B[0m         name\u001B[38;5;241m=\u001B[39mname,\n\u001B[1;32m   3582\u001B[0m         flavor\u001B[38;5;241m=\u001B[39mmlflow\u001B[38;5;241m.\u001B[39mpyfunc,\n\u001B[1;32m   3583\u001B[0m         loader_module\u001B[38;5;241m=\u001B[39mloader_module,\n\u001B[1;32m   3584\u001B[0m         data_path\u001B[38;5;241m=\u001B[39mdata_path,\n\u001B[1;32m   3585\u001B[0m         code_paths\u001B[38;5;241m=\u001B[39mcode_paths,\n\u001B[1;32m   3586\u001B[0m         python_model\u001B[38;5;241m=\u001B[39mpython_model,\n\u001B[1;32m   3587\u001B[0m         artifacts\u001B[38;5;241m=\u001B[39martifacts,\n\u001B[1;32m   3588\u001B[0m         conda_env\u001B[38;5;241m=\u001B[39mconda_env,\n\u001B[1;32m   3589\u001B[0m         registered_model_name\u001B[38;5;241m=\u001B[39mregistered_model_name,\n\u001B[1;32m   3590\u001B[0m         signature\u001B[38;5;241m=\u001B[39msignature,\n\u001B[1;32m   3591\u001B[0m         input_example\u001B[38;5;241m=\u001B[39minput_example,\n\u001B[1;32m   3592\u001B[0m         await_registration_for\u001B[38;5;241m=\u001B[39mawait_registration_for,\n\u001B[1;32m   3593\u001B[0m         pip_requirements\u001B[38;5;241m=\u001B[39mpip_requirements,\n\u001B[1;32m   3594\u001B[0m         extra_pip_requirements\u001B[38;5;241m=\u001B[39mextra_pip_requirements,\n\u001B[1;32m   3595\u001B[0m         metadata\u001B[38;5;241m=\u001B[39mmetadata,\n\u001B[1;32m   3596\u001B[0m         prompts\u001B[38;5;241m=\u001B[39mprompts,\n\u001B[1;32m   3597\u001B[0m         model_config\u001B[38;5;241m=\u001B[39mmodel_config,\n\u001B[1;32m   3598\u001B[0m         streamable\u001B[38;5;241m=\u001B[39mstreamable,\n\u001B[1;32m   3599\u001B[0m         resources\u001B[38;5;241m=\u001B[39mresources,\n\u001B[1;32m   3600\u001B[0m         infer_code_paths\u001B[38;5;241m=\u001B[39minfer_code_paths,\n\u001B[1;32m   3601\u001B[0m         auth_policy\u001B[38;5;241m=\u001B[39mauth_policy,\n\u001B[1;32m   3602\u001B[0m         params\u001B[38;5;241m=\u001B[39mparams,\n\u001B[1;32m   3603\u001B[0m         tags\u001B[38;5;241m=\u001B[39mtags,\n\u001B[1;32m   3604\u001B[0m         model_type\u001B[38;5;241m=\u001B[39mmodel_type,\n\u001B[1;32m   3605\u001B[0m         step\u001B[38;5;241m=\u001B[39mstep,\n\u001B[1;32m   3606\u001B[0m         model_id\u001B[38;5;241m=\u001B[39mmodel_id,\n\u001B[1;32m   3607\u001B[0m     )\n",
        "File \u001B[0;32m/databricks/python/lib/python3.12/site-packages/mlflow/models/model.py:1207\u001B[0m, in \u001B[0;36mModel.log\u001B[0;34m(cls, artifact_path, flavor, registered_model_name, await_registration_for, metadata, run_id, resources, auth_policy, prompts, name, model_type, params, tags, step, model_id, **kwargs)\u001B[0m\n\u001B[1;32m   1195\u001B[0m     prompts \u001B[38;5;241m=\u001B[39m [pr\u001B[38;5;241m.\u001B[39muri \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(pr, Prompt) \u001B[38;5;28;01melse\u001B[39;00m pr \u001B[38;5;28;01mfor\u001B[39;00m pr \u001B[38;5;129;01min\u001B[39;00m prompts]\n\u001B[1;32m   1197\u001B[0m mlflow_model \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mcls\u001B[39m(\n\u001B[1;32m   1198\u001B[0m     artifact_path\u001B[38;5;241m=\u001B[39mmodel\u001B[38;5;241m.\u001B[39martifact_location,\n\u001B[1;32m   1199\u001B[0m     model_uuid\u001B[38;5;241m=\u001B[39mmodel\u001B[38;5;241m.\u001B[39mmodel_id,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1205\u001B[0m     model_id\u001B[38;5;241m=\u001B[39mmodel\u001B[38;5;241m.\u001B[39mmodel_id,\n\u001B[1;32m   1206\u001B[0m )\n\u001B[0;32m-> 1207\u001B[0m flavor\u001B[38;5;241m.\u001B[39msave_model(path\u001B[38;5;241m=\u001B[39mlocal_path, mlflow_model\u001B[38;5;241m=\u001B[39mmlflow_model, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m   1208\u001B[0m \u001B[38;5;66;03m# `save_model` calls `load_model` to infer the model requirements, which may result\u001B[39;00m\n\u001B[1;32m   1209\u001B[0m \u001B[38;5;66;03m# in __pycache__ directories being created in the model directory.\u001B[39;00m\n\u001B[1;32m   1210\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m pycache \u001B[38;5;129;01min\u001B[39;00m Path(local_path)\u001B[38;5;241m.\u001B[39mrglob(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__pycache__\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n",
        "File \u001B[0;32m/databricks/python/lib/python3.12/site-packages/mlflow/tracing/provider.py:439\u001B[0m, in \u001B[0;36mtrace_disabled.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    437\u001B[0m             enable()\n\u001B[1;32m    438\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 439\u001B[0m         is_func_called, result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m, f(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    440\u001B[0m \u001B[38;5;66;03m# We should only catch the exception from disable() and enable()\u001B[39;00m\n\u001B[1;32m    441\u001B[0m \u001B[38;5;66;03m# and let other exceptions propagate.\u001B[39;00m\n\u001B[1;32m    442\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m MlflowTracingException \u001B[38;5;28;01mas\u001B[39;00m e:\n",
        "File \u001B[0;32m/databricks/python/lib/python3.12/site-packages/mlflow/pyfunc/__init__.py:3182\u001B[0m, in \u001B[0;36msave_model\u001B[0;34m(path, loader_module, data_path, code_paths, infer_code_paths, conda_env, mlflow_model, python_model, artifacts, signature, input_example, pip_requirements, extra_pip_requirements, metadata, model_config, streamable, resources, auth_policy, **kwargs)\u001B[0m\n\u001B[1;32m   3180\u001B[0m \u001B[38;5;66;03m# Load context before calling predict to ensure necessary artifacts are available\u001B[39;00m\n\u001B[1;32m   3181\u001B[0m context \u001B[38;5;241m=\u001B[39m PythonModelContext(artifacts, model_config)\n\u001B[0;32m-> 3182\u001B[0m model_for_signature_inference\u001B[38;5;241m.\u001B[39mload_context(context)\n\u001B[1;32m   3183\u001B[0m type_hint_from_example \u001B[38;5;241m=\u001B[39m _is_type_hint_from_example(type_hints\u001B[38;5;241m.\u001B[39minput)\n\u001B[1;32m   3184\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m type_hint_from_example:\n",
        "File \u001B[0;32m/tmp/rag_model_from_code.py:25\u001B[0m, in \u001B[0;36mRAGModel.load_context\u001B[0;34m(self, context)\u001B[0m\n\u001B[1;32m     23\u001B[0m aoai_key \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mgetenv(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAZURE_OPENAI_API_KEY\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     24\u001B[0m aoai_version \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mgetenv(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAZURE_OPENAI_API_VERSION\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m---> 25\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (aoai_endpoint \u001B[38;5;129;01mand\u001B[39;00m aoai_key \u001B[38;5;129;01mand\u001B[39;00m aoai_version):\n\u001B[1;32m     26\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMissing AOAI env vars.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     28\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclient \u001B[38;5;241m=\u001B[39m AzureOpenAI(\n\u001B[1;32m     29\u001B[0m     api_key\u001B[38;5;241m=\u001B[39maoai_key,\n\u001B[1;32m     30\u001B[0m     api_version\u001B[38;5;241m=\u001B[39maoai_version,\n\u001B[1;32m     31\u001B[0m     azure_endpoint\u001B[38;5;241m=\u001B[39maoai_endpoint,\n\u001B[1;32m     32\u001B[0m )\n",
        "\u001B[0;31mRuntimeError\u001B[0m: Missing DATABRICKS_HOST / DATABRICKS_TOKEN. Set these in the Serving endpoint environment variables."
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Models-from-Code RAG model (SERVING-SAFE)\n",
    "# - Vector Search auth via env vars (DATABRICKS_HOST / DATABRICKS_TOKEN)\n",
    "# - Azure OpenAI via env vars (AZURE_OPENAI_*)\n",
    "# - dbutils only used OUTSIDE the model, for notebook convenience\n",
    "# ============================================================\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "\n",
    "# -----------------------------\n",
    "# 0) (Notebook only) set env vars from secrets if not already set\n",
    "#    Serving will NOT use dbutils, so this is only to make notebook tests work.\n",
    "# -----------------------------\n",
    "if not os.getenv(\"AZURE_OPENAI_ENDPOINT\"):\n",
    "    os.environ[\"AZURE_OPENAI_ENDPOINT\"] = dbutils.secrets.get(\"aoai-scope\", \"openai-api-base\")\n",
    "if not os.getenv(\"AZURE_OPENAI_API_KEY\"):\n",
    "    os.environ[\"AZURE_OPENAI_API_KEY\"] = dbutils.secrets.get(\"aoai-scope\", \"openai-api-key\")\n",
    "if not os.getenv(\"AZURE_OPENAI_API_VERSION\"):\n",
    "    os.environ[\"AZURE_OPENAI_API_VERSION\"] = dbutils.secrets.get(\"aoai-scope\", \"openai-api-version\")\n",
    "\n",
    "# IMPORTANT: Serving needs these too (set in Serving endpoint config)\n",
    "# For notebook testing, you can set them here once if you want:\n",
    "# os.environ[\"DATABRICKS_HOST\"] = \"https://eastus2-c3.azuredatabricks.net\"\n",
    "# os.environ[\"DATABRICKS_TOKEN\"] = dbutils.secrets.get(\"your-scope\", \"your-pat-key\")\n",
    "\n",
    "print(\"✅ AOAI env vars present:\",\n",
    "      bool(os.getenv(\"AZURE_OPENAI_ENDPOINT\")),\n",
    "      bool(os.getenv(\"AZURE_OPENAI_API_KEY\")),\n",
    "      bool(os.getenv(\"AZURE_OPENAI_API_VERSION\")))\n",
    "\n",
    "print(\"✅ DBX env vars present:\",\n",
    "      bool(os.getenv(\"DATABRICKS_HOST\")),\n",
    "      bool(os.getenv(\"DATABRICKS_TOKEN\")))\n",
    "\n",
    "# -----------------------------\n",
    "# 1) Config\n",
    "# -----------------------------\n",
    "ENDPOINT_NAME = \"vector_search_endpoint\"\n",
    "INDEX_NAME = \"adb_genai_super_locust.rag.diabetes_faq_index\"\n",
    "\n",
    "try:\n",
    "    DEPLOYMENT_NAME = deployment_name\n",
    "except NameError:\n",
    "    DEPLOYMENT_NAME = \"YOUR_AZURE_OPENAI_DEPLOYMENT_NAME\"\n",
    "\n",
    "# -----------------------------\n",
    "# 2) Write serving-safe model script (NO dbutils inside)\n",
    "# -----------------------------\n",
    "script_path = \"/tmp/rag_model_from_code.py\"\n",
    "\n",
    "script = f'''\n",
    "import os\n",
    "import pandas as pd\n",
    "from typing import Any\n",
    "from mlflow.pyfunc import PythonModel\n",
    "from mlflow.models import set_model\n",
    "from databricks.vector_search.client import VectorSearchClient\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "ENDPOINT_NAME = \"{ENDPOINT_NAME}\"\n",
    "INDEX_NAME = \"{INDEX_NAME}\"\n",
    "DEPLOYMENT_NAME = \"{DEPLOYMENT_NAME}\"\n",
    "\n",
    "class RAGModel(PythonModel):\n",
    "    def __init__(self, top_k: int = 1):\n",
    "        self.top_k = top_k\n",
    "\n",
    "    def load_context(self, context: Any) -> None:\n",
    "        # -------------------------\n",
    "        # Vector Search auth (Serving-safe)\n",
    "        # -------------------------\n",
    "        host = os.getenv(\"DATABRICKS_HOST\")\n",
    "        token = os.getenv(\"DATABRICKS_TOKEN\")\n",
    "        if not (host and token):\n",
    "            raise RuntimeError(\n",
    "                \"Missing DATABRICKS_HOST / DATABRICKS_TOKEN. \"\n",
    "                \"Set these in the Serving endpoint environment variables.\"\n",
    "            )\n",
    "\n",
    "        # VectorSearchClient constructor can vary slightly by workspace version,\n",
    "        # so we try common parameter names.\n",
    "        try:\n",
    "            vsc = VectorSearchClient(workspace_url=host, personal_access_token=token, disable_notice=True)\n",
    "        except TypeError:\n",
    "            try:\n",
    "                vsc = VectorSearchClient(host=host, token=token, disable_notice=True)\n",
    "            except TypeError as exc:\n",
    "                raise RuntimeError(f\"VectorSearchClient auth init failed: {{exc}}\") from exc\n",
    "\n",
    "        self.index = vsc.get_index(ENDPOINT_NAME, INDEX_NAME)\n",
    "\n",
    "        # -------------------------\n",
    "        # Azure OpenAI auth (Serving-safe)\n",
    "        # -------------------------\n",
    "        aoai_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "        aoai_key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "        aoai_version = os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
    "        if not (aoai_endpoint and aoai_key and aoai_version):\n",
    "            raise RuntimeError(\n",
    "                \"Missing Azure OpenAI env vars. \"\n",
    "                \"Set AZURE_OPENAI_ENDPOINT / AZURE_OPENAI_API_KEY / AZURE_OPENAI_API_VERSION \"\n",
    "                \"in the Serving endpoint environment variables.\"\n",
    "            )\n",
    "\n",
    "        self.client = AzureOpenAI(\n",
    "            api_key=aoai_key,\n",
    "            api_version=aoai_version,\n",
    "            azure_endpoint=aoai_endpoint,\n",
    "        )\n",
    "\n",
    "    def _retrieve(self, q: str) -> str:\n",
    "        res = self.index.similarity_search(\n",
    "            query_text=q,\n",
    "            columns=[\"Topic\", \"Description\"],\n",
    "            num_results=self.top_k,\n",
    "        )\n",
    "        return str(res)\n",
    "\n",
    "    def _chat(self, q: str, ctx: str) -> str:\n",
    "        resp = self.client.chat.completions.create(\n",
    "            model=DEPLOYMENT_NAME,\n",
    "            messages=[\n",
    "                {{\"role\": \"system\", \"content\": \"Answer using the supporting knowledge.\"}},\n",
    "                {{\"role\": \"user\", \"content\": f\"user query: {{q}}\\\\nsupporting knowledge: {{ctx}}\" }},\n",
    "            ],\n",
    "        )\n",
    "        return resp.choices[0].message.content\n",
    "\n",
    "    def predict(self, context: Any, model_input: pd.DataFrame) -> pd.DataFrame:\n",
    "        queries = model_input[\"query\"].astype(str).tolist()\n",
    "        answers = []\n",
    "        for q in queries:\n",
    "            ctx = self._retrieve(q)\n",
    "            answers.append(self._chat(q, ctx))\n",
    "        return pd.DataFrame({{\"answer\": answers}})\n",
    "\n",
    "set_model(RAGModel(top_k=1))\n",
    "'''\n",
    "\n",
    "with open(script_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(script)\n",
    "\n",
    "print(f\"✅ Wrote model script: {script_path}\")\n",
    "\n",
    "# -----------------------------\n",
    "# 3) Log model + keep model_uri\n",
    "# -----------------------------\n",
    "input_example = pd.DataFrame([{\"query\": \"what is diabetes?\"}])\n",
    "\n",
    "with mlflow.start_run() as run:\n",
    "    model_info = mlflow.pyfunc.log_model(\n",
    "        python_model=script_path,\n",
    "        name=\"rag_model\",\n",
    "        input_example=input_example,\n",
    "        pip_requirements=[\n",
    "            \"mlflow\",\n",
    "            \"pandas\",\n",
    "            \"openai\",\n",
    "            \"databricks-vectorsearch\",\n",
    "        ],\n",
    "    )\n",
    "    model_uri = model_info.model_uri\n",
    "    mlflow.log_text(model_uri, \"model_uri.txt\")\n",
    "\n",
    "print(\"✅ Logged model_uri:\", model_uri)\n",
    "print(\"✅ Run ID:\", run.info.run_id)\n",
    "\n",
    "# -----------------------------\n",
    "# 4) Quick notebook test (optional)\n",
    "# -----------------------------\n",
    "loaded = mlflow.pyfunc.load_model(model_uri)\n",
    "print(loaded.predict(pd.DataFrame([{\"query\": \"what is diabetes?\"}])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6200e513-13f8-41f2-98ff-bb0e2389f1a9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Loading Our Saved Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "af11e4fc-adcf-440f-9487-09529b0290dd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       ""
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {
        "CATALOG": "",
        "EXTERNAL_LOCATION": "uc-external-location",
        "SCHEMA": "rag",
        "VOLUME": "raw"
       },
       "datasetInfos": [],
       "jupyterProps": null,
       "metadata": {
        "errorSummary": "Command skipped"
       },
       "removedWidgets": [],
       "sqlProps": null,
       "stackFrames": [],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ============================================================\n",
    "# LOAD THE LATEST LOGGED MODEL (from the previous cell)\n",
    "# ============================================================\n",
    "\n",
    "import mlflow\n",
    "import pandas as pd\n",
    "\n",
    "# This variable is created in the previous cell:\n",
    "#   model_uri = model_info.model_uri\n",
    "if \"model_uri\" not in globals():\n",
    "    raise RuntimeError(\n",
    "        \"model_uri is not defined. Run the previous 'log model' cell first.\"\n",
    "    )\n",
    "\n",
    "loaded_pyfunc_model = mlflow.pyfunc.load_model(model_uri)\n",
    "\n",
    "# Quick sanity test\n",
    "test_df = pd.DataFrame([{\"query\": \"what is diabetes?\"}])\n",
    "print(\"✅ Loaded model from:\", model_uri)\n",
    "print(loaded_pyfunc_model.predict(test_df))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e94fa9c0-0a0a-49a3-b4f2-79c62dd3689a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Testing our Loaded/Saved Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5c3d63ae-7aaf-4a42-a027-ea70ffd973fc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       ""
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {
        "CATALOG": "",
        "EXTERNAL_LOCATION": "uc-external-location",
        "SCHEMA": "rag",
        "VOLUME": "raw"
       },
       "datasetInfos": [],
       "jupyterProps": null,
       "metadata": {
        "errorSummary": "Command skipped"
       },
       "removedWidgets": [],
       "sqlProps": null,
       "stackFrames": [],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_input = pd.DataFrame([{\"query\": \"what is diabetes?\"}])\n",
    "\n",
    "model_response = loaded_pyfunc_model.predict(model_input)\n",
    "\n",
    "print(model_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4a96d08f-156a-4b22-9dca-89a4ae8122f3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Logging our saved model as an artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1edcbf27-c6a9-4731-8096-a2c009366b53",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       ""
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {
        "CATALOG": "",
        "EXTERNAL_LOCATION": "uc-external-location",
        "SCHEMA": "rag",
        "VOLUME": "raw"
       },
       "datasetInfos": [],
       "jupyterProps": null,
       "metadata": {
        "errorSummary": "Command skipped"
       },
       "removedWidgets": [],
       "sqlProps": null,
       "stackFrames": [],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "# Log the model as an artifact\n",
    "with mlflow.start_run() as run:\n",
    "    mlflow.log_artifacts(local_dir=model_path, artifact_path=\"rag_model\")\n",
    "    print(f\"Model logged with run ID: {run.info.run_id}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c9dcae90-325c-45d9-b59a-d456dd67ce32",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       ""
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {
        "CATALOG": "",
        "EXTERNAL_LOCATION": "uc-external-location",
        "SCHEMA": "rag",
        "VOLUME": "raw"
       },
       "datasetInfos": [],
       "jupyterProps": null,
       "metadata": {
        "errorSummary": "Command skipped"
       },
       "removedWidgets": [],
       "sqlProps": null,
       "stackFrames": [],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "mlflow.set_registry_uri(\"databricks\")  # workspace registry (not UC)\n",
    "registered = mlflow.register_model(model_uri=model_uri, name=\"rag_model\")\n",
    "\n",
    "print(\"✅ Registered:\", registered.name, \"v\", registered.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6d43f0b1-f473-443f-886d-73b8d7ed8499",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Inferencing the real-time endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "173317f0-c104-4aa3-9f4d-04957d4f69ed",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       ""
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {
        "CATALOG": "",
        "EXTERNAL_LOCATION": "uc-external-location",
        "SCHEMA": "rag",
        "VOLUME": "raw"
       },
       "datasetInfos": [],
       "jupyterProps": null,
       "metadata": {
        "errorSummary": "Command skipped"
       },
       "removedWidgets": [],
       "sqlProps": null,
       "stackFrames": [],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "{\n",
    "  \"dataframe_records\":[\n",
    "    {\n",
    "        \"query\":\"what is diabetes?\"\n",
    "    }\n",
    "  ]\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": -1,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "rag.ipynb",
   "widgets": {
    "CATALOG": {
     "currentValue": "",
     "nuid": "f530fd87-72c5-48eb-bdfd-350f736338ad",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "",
      "label": null,
      "name": "CATALOG",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "",
      "label": null,
      "name": "CATALOG",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "EXTERNAL_LOCATION": {
     "currentValue": "uc-external-location",
     "nuid": "51d3ee2f-4473-4bb1-bcef-4f7b9ffc2ad3",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "uc-external-location",
      "label": null,
      "name": "EXTERNAL_LOCATION",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "uc-external-location",
      "label": null,
      "name": "EXTERNAL_LOCATION",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "SCHEMA": {
     "currentValue": "rag",
     "nuid": "af751584-55ac-4ed0-9337-ca8b8b115588",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "rag",
      "label": null,
      "name": "SCHEMA",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "rag",
      "label": null,
      "name": "SCHEMA",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "VOLUME": {
     "currentValue": "raw",
     "nuid": "e321e01d-a077-4419-8467-04091a8f309d",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "raw",
      "label": null,
      "name": "VOLUME",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "raw",
      "label": null,
      "name": "VOLUME",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    }
   }
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}